{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = preprocess_image(\"/InvoiceProcessing/data/invoice2.jpg\")\n",
    "cv2.imwrite(\"/InvoiceProcessing/data/pp2_invoice2.jpg\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.49.0\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.49.0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    print(generated_ids)\n",
    "    text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    #return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 35,  2]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "':'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text(\"/InvoiceProcessing/data/pp2_invoice2.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values shape: torch.Size([1, 3, 384, 384])\n",
      "Extracted Text: :\n"
     ]
    }
   ],
   "source": [
    "def eextract_text(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # Check if image is processed correctly\n",
    "        pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "        print(\"Pixel values shape:\", pixel_values.shape)  # Should not be empty\n",
    "\n",
    "        # Generate text\n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "        # Debug output\n",
    "        print(\"Extracted Text:\", text)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        return None\n",
    "\n",
    "text_output = eextract_text(\"/InvoiceProcessing/data/pp2_invoice2.jpg\")  # Change to your image path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel values shape: torch.Size([1, 3, 384, 384])\n",
      "Generated IDs: tensor([[ 2, 35,  2]])\n",
      "Extracted Text: :\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Use a test image from the internet\n",
    "image = Image.open(\"/InvoiceProcessing/data/pp2_invoice2.jpg\").convert(\"RGB\")  # Use your image\n",
    "\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "print(\"Pixel values shape:\", pixel_values.shape)  # Should be (1, 3, 384, 384)\n",
    "\n",
    "# Generate text\n",
    "generated_ids = model.generate(pixel_values)\n",
    "print(\"Generated IDs:\", generated_ids)  # Check if IDs are generated\n",
    "\n",
    "# Decode text\n",
    "text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(\"Extracted Text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "def extract_text_paddle(image_path):\n",
    "    ocr = PaddleOCR(lang='en')  # Supports multiple languages\n",
    "    result = ocr.ocr(image_path, cls=True)\n",
    "    \n",
    "    extracted_text = []\n",
    "    for line in result:\n",
    "        for word in line:\n",
    "            extracted_text.append(word[1][0])  # Get detected text\n",
    "    \n",
    "    return \" \".join(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/11 20:21:48] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='f:\\\\InvoiceProcessing\\\\venv\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/11 20:21:52] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2025/03/11 20:21:53] ppocr DEBUG: dt_boxes num : 27, elapsed : 0.9505178928375244\n",
      "[2025/03/11 20:21:56] ppocr DEBUG: rec_res num  : 27, elapsed : 3.439005136489868\n",
      "PaddleOCR Extracted Text: KERALA RESJAURANT LAAUHITE THC!E . BANGALORE 8ILL NO : 06739 DATE: 22.:5/ :7 ITEX NAME QTy PRICE ANOUHT 8P 12.00 96.00 CHAPATHI 1P 120.00 120.00 CHICTEN ROAS? 1p 55.00 55.00 EGG ROAST 271.00 /917:10.000 JOTAL I1EN(S):3 7271.00 TOtAL THANX YOU\n"
     ]
    }
   ],
   "source": [
    "text_paddle = extract_text_paddle(\"/InvoiceProcessing/data/pp2_invoice2.jpg\")\n",
    "print(\"PaddleOCR Extracted Text:\", text_paddle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/11 20:21:35] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='f:\\\\InvoiceProcessing\\\\venv\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/11 20:21:39] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2025/03/11 20:21:40] ppocr DEBUG: dt_boxes num : 42, elapsed : 0.8539235591888428\n",
      "[2025/03/11 20:21:47] ppocr DEBUG: rec_res num  : 42, elapsed : 6.891994953155518\n",
      "PaddleOCR Extracted Text: TAx Inoice 00 Hyper Drive Fashions #167, Hyper Drive lane. 2nd Croes Sobha Apartment Roed, Sarjapur ORR Beltandur Bengaluru. Karnataka. S60103 GSTN: 457042S Customer : Aremka Oeshoonde Dame : 12/07/2017 Py. Type : Cash CR: 01 BILL NO : Hyp-400042 Hem Narne HSN Oty. Banic Rate Total Ce5o Btack Soid V2323 2 847.46 1.694.92 Neck Sweater L P. Stiond ehue V. 3232 2 677.97 1.355.93 Nock Swoaner L Phosphorus Red S 3213 1 422.88 422.88 V Nack T-$hits L. CGST : 274.58 SGST : 274.58 CESS : 0.00 Grand Totel : 4,099.00 THANK YOU FOR SHOPPING\n"
     ]
    }
   ],
   "source": [
    "text_paddle1 = extract_text_paddle(\"/InvoiceProcessing/data/pp2_invoice1.jpg\")\n",
    "print(\"PaddleOCR Extracted Text:\", text_paddle1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processorl = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "modell = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_invoice_fields(image_path, text):\n",
    "    encoding = processorl(image_path, text, return_tensors=\"pt\")\n",
    "    outputs = modell(**encoding)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_invoice_fields(image_path, text):\n",
    "    # Load image using PIL\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Convert to RGB format\n",
    "\n",
    "    # Encode image and text\n",
    "    encoding = processorl(images=image, text=text, return_tensors=\"pt\")\n",
    "\n",
    "    # Run model\n",
    "    outputs = modell(**encoding)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = \"/InvoiceProcessing/data/pp2_invoice1.jpg\"\n",
    "#text_paddle1 = \"Your extracted OCR text here\"  # Replace with actual text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/11 20:41:53] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='f:\\\\InvoiceProcessing\\\\venv\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\Devaraj/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/11 20:42:15] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2025/03/11 20:42:16] ppocr DEBUG: dt_boxes num : 42, elapsed : 0.47299623489379883\n",
      "[2025/03/11 20:42:22] ppocr DEBUG: rec_res num  : 42, elapsed : 6.0560033321380615\n"
     ]
    },
    {
     "ename": "TesseractNotFoundError",
     "evalue": "tesseract is not installed or it's not in your PATH. See README file for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\pytesseract\\pytesseract.py:451\u001b[0m, in \u001b[0;36mget_tesseract_version\u001b[1;34m()\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 451\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtesseract_cmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--version\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\subprocess.py:420\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    421\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\subprocess.py:501\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\subprocess.py:966\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    964\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\subprocess.py:1435\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1435\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1442\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1444\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTesseractNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     31\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/InvoiceProcessing/data/pp2_invoice1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 32\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mextract_invoice_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n",
      "Cell \u001b[1;32mIn[60], line 22\u001b[0m, in \u001b[0;36mextract_invoice_fields\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([line[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m ocr_result[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Encode image and extracted text\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextracted_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Run model\u001b[39;00m\n\u001b[0;32m     25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoding)\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\transformers\\models\\layoutlmv3\\processing_layoutlmv3.py:115\u001b[0m, in \u001b[0;36mLayoutLMv3Processor.__call__\u001b[1;34m(self, images, text, text_pair, boxes, word_labels, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot provide word labels if you initialized the image processor with apply_ocr set to True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# first, apply the image processor\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# second, apply the tokenizer\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_processor\u001b[38;5;241m.\u001b[39mapply_ocr \u001b[38;5;129;01mand\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\transformers\\image_processing_utils.py:42\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[1;34m(self, images, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[0;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\transformers\\utils\\generic.py:854\u001b[0m, in \u001b[0;36mfilter_out_non_signature_kwargs.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m         cls_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following named arguments are not valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcls_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and were ignored: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minvalid_kwargs_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    851\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    852\u001b[0m     )\n\u001b[1;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalid_kwargs)\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\transformers\\models\\layoutlmv3\\image_processing_layoutlmv3.py:343\u001b[0m, in \u001b[0;36mLayoutLMv3ImageProcessor.preprocess\u001b[1;34m(self, images, do_resize, size, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, apply_ocr, ocr_lang, tesseract_config, return_tensors, data_format, input_data_format)\u001b[0m\n\u001b[0;32m    341\u001b[0m boxes_batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m--> 343\u001b[0m     words, boxes \u001b[38;5;241m=\u001b[39m \u001b[43mapply_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mocr_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesseract_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m     words_batch\u001b[38;5;241m.\u001b[39mappend(words)\n\u001b[0;32m    345\u001b[0m     boxes_batch\u001b[38;5;241m.\u001b[39mappend(boxes)\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\transformers\\models\\layoutlmv3\\image_processing_layoutlmv3.py:76\u001b[0m, in \u001b[0;36mapply_tesseract\u001b[1;34m(image, lang, tesseract_config, input_data_format)\u001b[0m\n\u001b[0;32m     74\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m to_pil_image(image, input_data_format\u001b[38;5;241m=\u001b[39minput_data_format)\n\u001b[0;32m     75\u001b[0m image_width, image_height \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m---> 76\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtesseract_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m words, left, top, width, height \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# filter empty words and corresponding coordinates\u001b[39;00m\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\pytesseract\\pytesseract.py:590\u001b[0m, in \u001b[0;36mimage_to_data\u001b[1;34m(image, lang, config, nice, output_type, timeout, pandas_config)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimage_to_data\u001b[39m(\n\u001b[0;32m    577\u001b[0m     image,\n\u001b[0;32m    578\u001b[0m     lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    583\u001b[0m     pandas_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    584\u001b[0m ):\n\u001b[0;32m    585\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;124;03m    Returns string containing box boundaries, confidences,\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;124;03m    and other information. Requires Tesseract 3.05+\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mget_tesseract_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m TESSERACT_MIN_VERSION:\n\u001b[0;32m    591\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TSVNotSupported()\n\u001b[0;32m    593\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-c tessedit_create_tsv=1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\pytesseract\\pytesseract.py:163\u001b[0m, in \u001b[0;36mrun_once.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcached\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m wrapper\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m wrapper:\n\u001b[1;32m--> 163\u001b[0m         wrapper\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32mf:\\InvoiceProcessing\\venv\\lib\\site-packages\\pytesseract\\pytesseract.py:458\u001b[0m, in \u001b[0;36mget_tesseract_version\u001b[1;34m()\u001b[0m\n\u001b[0;32m    451\u001b[0m     output \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mcheck_output(\n\u001b[0;32m    452\u001b[0m         [tesseract_cmd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--version\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    453\u001b[0m         stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT,\n\u001b[0;32m    454\u001b[0m         env\u001b[38;5;241m=\u001b[39menviron,\n\u001b[0;32m    455\u001b[0m         stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mDEVNULL,\n\u001b[0;32m    456\u001b[0m     )\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[0;32m    460\u001b[0m raw_version \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdecode(DEFAULT_ENCODING)\n\u001b[0;32m    461\u001b[0m str_version, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m raw_version\u001b[38;5;241m.\u001b[39mlstrip(string\u001b[38;5;241m.\u001b[39mprintable[\u001b[38;5;241m10\u001b[39m:])\u001b[38;5;241m.\u001b[39mpartition(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTesseractNotFoundError\u001b[0m: tesseract is not installed or it's not in your PATH. See README file for more information."
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForTokenClassification\n",
    "import torch\n",
    "\n",
    "# Initialize PaddleOCR\n",
    "ocr = PaddleOCR(lang='en')\n",
    "\n",
    "# Initialize LayoutLMv3\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "model = LayoutLMv3ForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "\n",
    "def extract_invoice_fields(image_path):\n",
    "    # Load image with PIL\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Extract text using PaddleOCR\n",
    "    ocr_result = ocr.ocr(image_path, cls=True)\n",
    "    extracted_text = \" \".join([line[1][0] for line in ocr_result[0]])\n",
    "\n",
    "    # Encode image and extracted text\n",
    "    encoding = processor(images=image, text=extracted_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Run model\n",
    "    outputs = model(**encoding)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/InvoiceProcessing/data/pp2_invoice1.jpg\"\n",
    "predictions = extract_invoice_fields(image_path)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
